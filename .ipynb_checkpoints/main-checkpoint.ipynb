{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo tutto \n",
    "import pandas as pd\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pathlib \n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from datetime import timedelta,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dichiaro i vari percorsi \n",
    "path_abs = str(pathlib.Path().parent.absolute())\n",
    "path_materiale = \"{}/materiale/results/\".format(path_abs)\n",
    "file_path = \"{}/materiale/\".format(path_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definizione var ambiente per decidere output\n",
    "#se OUT e definita al momento del dockerrun allora la segue, sennò di default non printa nulla\n",
    "operation = \"\"\n",
    "'''\n",
    "os.environ['OPERATION'] = \"print\"\n",
    "os.environ['PROD'] = \"print\"\n",
    "'''\n",
    "\n",
    "if os.getenv(\"OPERATION\") is not None:\n",
    "    operation = os.getenv(\"OPERATION\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non loggo perchè la creo direttamente nel dockerfile\n",
    "def check_dir(path_materiale):\n",
    "    #in qualunque caso istanzio il logger\n",
    "    \n",
    "    if os.path.isdir(path_materiale) == False:\n",
    "        try: \n",
    "            os.makedirs(path_materiale)\n",
    "            \n",
    "        except OSError as error:\n",
    "            print(\"error\")\n",
    "    \n",
    "    #se esiste non loggo nulla\n",
    "    if os.path.isdir(path_materiale) == True:\n",
    "        #print(\"la directory esiste\")\n",
    "        pass\n",
    "\n",
    "\n",
    "res = check_dir(path_materiale)\n",
    "\n",
    "logging.basicConfig(handlers=[logging.FileHandler(filename=path_materiale+'filelog.log', encoding='utf-8', mode='a+')],format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#CONTROLLO ESISTENZA PERCORSI E FILE\n",
    "#COLLEZIONO LOG\n",
    "#####################################\n",
    "#se si trova nella cartella principale lo carico da la e il path è abs sennò lo carico dentro materiale in modo da darlo anche all'utente\n",
    "\n",
    "file_locale = \"\"\n",
    "def down_file(url, filename):\n",
    "    try:\n",
    "        logger.info(\"sto scaricando il file\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path+filename, 'wb') as f:\n",
    "                for chunk in response.iter_content():\n",
    "                    if chunk: # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "    \n",
    "        else:\n",
    "            logger.info(\"Errore diverso da 200\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.info(\"Errore nel scaricare il file\")\n",
    "    \n",
    "    return file_path+filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file():\n",
    "    file_list = []\n",
    "    \n",
    "    #Get the list of all files and directories\n",
    "    dir_list = os.listdir(file_path)\n",
    "    file_count = 0\n",
    "    for file in dir_list:\n",
    "        if os.path.isfile(file_path+file):\n",
    "            file_count = file_count+1\n",
    "    \n",
    "    #se non ci sono file per forza lo scarico\n",
    "    if file_count == 0:\n",
    "        #print(\"file non trovato lo scarico\")\n",
    "        #se non trovo il file, lo scarico\n",
    "        url = \"https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv\"\n",
    "        file_list.append({'titanic': down_file(url,\"titanic.csv\")})\n",
    "        logger.info(\"file titanic scaricato\")\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    #controllo se esiste il un file titanic.csv\n",
    "    for file in dir_list:\n",
    "        if os.path.isfile(file_path+file):\n",
    "            if \"csv\" and \"titanic\" in file:\n",
    "                #print(file)\n",
    "\n",
    "                logger.info(\"File titanic trovato in locale\")\n",
    "\n",
    "            #se esiste ritorno il nome del file e abbiamo vinto\n",
    "                file_list.append({'titanic': \"{}/{}\".format(file_path,file)}) \n",
    "                #print(\"file trovato\")\n",
    "                return file_list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vado nel path materiale e seleziono il file\n",
    "check_dir(path_materiale)\n",
    "filename = check_file()\n",
    "\n",
    "#leggo il file csv\n",
    "file = str(file_path +'titanic.csv')\n",
    "df = pd.read_csv(file, encoding = \"utf-8 \")\n",
    "logger.info(\"csv convertito in dataframe\")\n",
    "\n",
    "df['count_survived']=df['Survived'].value_counts()\n",
    "df['class_summed']=df['Pclass'].value_counts()\n",
    "df['eta_count']= df[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_param = []\n",
    "l_param.append({\"value\":\"-?\",\"desc\":\"Elenca tutti i possibili campi ricercabili\"})\n",
    "l_param.append({\"value\":\"-survived\",\"desc\":\"Passeggeri sopravvissuti\"})\n",
    "l_param.append({\"value\":\"-class\",\"desc\":\"Classe di appertenenza del passeggero\"})\n",
    "l_param.append({\"value\":\"-age\",\"desc\":\"età dei passeggeri\"})\n",
    "l_param.append({\"value\":\"-sex_class\",\"desc\":\"percentuale sopravvissuti per sesso e classe \"})\n",
    "\n",
    "def list_parameters():\n",
    "    print ('LISTA DELLE METRICHE A DISPOSIZIONE:\\n')\n",
    "    for i in l_param:\n",
    "        print(\"{}\\n-- {}\\n\\n\".format(i[\"value\"],i[\"desc\"]))\n",
    "\n",
    "def totale_sopravvissuti(): \n",
    "    logger.info(\"chiamata funzione totale_sopravvissuti\")\n",
    "\n",
    "    df['Survived']=np.where(df['Survived']==1 , 'sopravvissuti', 'deceduti')\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    titolo = \"Passeggeri sopravvissuti\"\n",
    "    plt.title(titolo, fontsize=15)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.barh(df[\"Survived\"],df['count_survived'])\n",
    "    filename = \"{}.png\".format(titolo)\n",
    "    plt.savefig(path_materiale+filename,bbox_inches='tight',dpi=300,transparent=False)\n",
    "    if operation == \"print\":\n",
    "        print(\"sopravvissuti: \" + str(df['count_survived'][1]))\n",
    "        print(\"non sopravvissuti: \" + str(df['count_survived'][0]))\n",
    "    \n",
    "def classe_viaggio():\n",
    "    logger.info(\"chiamata funzione classe_viaggio\")\n",
    "    titolo = \"Classe di appartenenza\"\n",
    "    df['prima_classe'] = np.where(df['Pclass']== 1 , 1 , 0)\n",
    "    df['seconda_classe'] = np.where(df['Pclass']== 2 , 1 , 0)\n",
    "    df['terza_classe'] = np.where(df['Pclass']== 3 , 1 , 0)\n",
    "    data = {'prima_classe': int((df['prima_classe']).sum()) , 'seconda_classe': int((df['seconda_classe']).sum()), 'terza_classe': int((df['terza_classe']).sum())}\n",
    "    names = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(names,values)\n",
    "    plt.title(titolo, fontsize=15)\n",
    "    filename = \"{}.png\".format(titolo)\n",
    "    plt.savefig(path_materiale+filename,bbox_inches='tight',dpi=300,transparent=False)\n",
    "    if operation == \"print\":\n",
    "        print(\"numero di sopravvissuti per classe di biglietto: \\n\" )\n",
    "        print(data)\n",
    "    \n",
    "def class_sex():\n",
    "    logger.info(\"chiamata funzione class_sex\")\n",
    "\n",
    "    titolo = \"percentuale_di_sopravvissuti_divisi_per_sesso_e_classe\"\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    g = sns.catplot(data=df, kind=\"bar\",x='Sex', y ='Survived',  hue=\"Pclass\", palette=\"dark\", alpha=.6, height=6)\n",
    "    g.despine(left=True)\n",
    "    g.set_axis_labels(\"\", \"% di sopravvissuti per sesso e classe \")\n",
    "    g.legend.set_title(\"\")\n",
    "    filename = \"{}.png\".format(titolo)\n",
    "    \n",
    "    #facciamo un try catch perchè catplot si comporta in modo anomalo randomicamente\n",
    "    \n",
    "    df['male_first']=np.where((df['Sex']=='male') & (df['Pclass']== 1), 1, 0)\n",
    "    df['male_second']=np.where((df['Sex']=='male')& (df['Pclass']==2), 1, 0)\n",
    "    df['male_third']=np.where((df['Sex']=='male')& (df['Pclass']== 3), 1, 0)\n",
    "    df['female_first']=np.where((df['Sex']=='female')& (df['Pclass']== 1), 1, 0)\n",
    "    df['female_second']=np.where((df['Sex']=='female')& (df['Pclass']== 2), 1, 0)\n",
    "    df['female_third']=np.where((df['Sex']=='female')& (df['Pclass']== 3), 1, 0)\n",
    "\n",
    "    data = {'male-first': int((df['male_first']).sum()) ,\n",
    "            'male_second': int((df['male_second']).sum()) , \n",
    "            'male_third': int((df['male_third']).sum()) ,\n",
    "            'female_first': int((df['female_first']).sum()) , \n",
    "            'female_second': int((df['female_second']).sum()) , \n",
    "            'female_third': int((df['female_third']).sum()) }\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        plt.savefig(path_materiale+filename,bbox_inches='tight',dpi=300,transparent=False)\n",
    "        logger.info(\"class_sex plot eseguito correttamente\")\n",
    "        if operation == \"print\":\n",
    "            print(\"passeggeri divisi per sesso e classe: \\n\")\n",
    "            print(data)\n",
    "\n",
    "    except:\n",
    "        logger.info(\"class_sex errori nella creazione del catplot\")\n",
    "\n",
    "def eta():\n",
    "    logger.info(\"chiamata funzione eta\")\n",
    "\n",
    "    titolo = \"eta_dei_passeggeri\"   \n",
    "    df['cat_age']=np.where(df['Age']<10, \"0-10\", df['Age'])\n",
    "    df['cat_age']=np.where(((df['Age']<20) & (df['Age']>=10)), \"10-20\", df['cat_age'])\n",
    "    df['cat_age']=np.where(((df['Age']<30) & (df['Age']>=20)), \"20-30\", df['cat_age'])\n",
    "    df['cat_age']=np.where(((df['Age']<40) & (df['Age']>=30)), \"30-40\", df['cat_age'])\n",
    "    df['cat_age']=np.where(((df['Age']<50) & (df['Age']>=40)), \"40-50\", df['cat_age'])\n",
    "    df['cat_age']=np.where(df['Age']>=50, \">50\", df['cat_age'])\n",
    "    \n",
    "    data = {'0-10': int((df['cat_age']==\"0-10\").sum()) , '10-20': int((df['cat_age']==\"10-20\").sum()), \n",
    "            '20-30': int((df['cat_age']==\"20-30\").sum()), '30-40': int((df['cat_age']==\"30-40\").sum()), \n",
    "            '40-50': int((df['cat_age']==\"40-50\").sum()), '>50': int((df['cat_age']==\">50\").sum())}\n",
    "    names = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(names,values)\n",
    "    plt.title(titolo, fontsize=15)\n",
    "    filename = \"{}.png\".format(titolo)\n",
    "    plt.savefig(path_materiale+filename,bbox_inches='tight',dpi=300,transparent=False)\n",
    "    if operation == \"print\":\n",
    "        print(\"eta dei passeggeri: \\n\" +str(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'male-first': 122, 'male_second': 108, 'male_third': 347, 'female_first': 94, 'female_second': 76, 'female_third': 144}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VEDIAMO QUALI SONO I PARAMETRI PASSATI E LANCIAMO LE FUNZIONI CORRISPONDENTI\n",
    "\n",
    "for i in range(1,len(sys.argv)):\n",
    "    command = sys.argv[i]\n",
    "    if command == \"-?\":\n",
    "        list_parameters()\n",
    "        quit()\n",
    "    if command == \"-survived\":\n",
    "        totale_sopravvissuti()\n",
    "    if command == \"-class\":\n",
    "        classe_viaggio()\n",
    "    if command == \"-age\":\n",
    "        eta()\n",
    "    if command == \"-sex_class\":\n",
    "        class_sex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SE NON SIAMO IN PROD CONVERTE IL NOTEBOOK, CANCELLA EVENTUALE BUILD PRECEDENTE E NE CREA UNA NUOVA\n",
    "if os.getenv(\"PROD\") == None:\n",
    "    command = \"jupyter nbconvert --to 'script' main.ipynb\"\n",
    "    os.system(command)\n",
    "    \n",
    "    #fermo ed elimino eventuali contenitori aperti in modo da poter cancellare e ribuildare l'immagine senza crearne di nuove\n",
    "    import subprocess\n",
    "    container_ids = subprocess.check_output(['docker', 'ps', '-aq'], encoding='ascii')\n",
    "    container_ids = container_ids.strip().split()\n",
    "    if container_ids:\n",
    "        subprocess.check_call(['docker', 'stop'] + container_ids)\n",
    "        subprocess.check_call(['docker', 'rm'] + container_ids)\n",
    "\n",
    "    #rimuovo tutte le immagini preesistenti di cloud_titanic        \n",
    "    command = \"docker rmi cloud_titanic\"\n",
    "    os.system(command)\n",
    "    \n",
    "    #command = \"docker run -e OPERATION = command -v cloud_titanic\"\n",
    "    #os.system(command)\n",
    "    \n",
    "    #command = \"docker run -v $(PWD) -e DATASET= titanic.csv\"\n",
    "    #os.system(command)\n",
    "    #command = \"\"\n",
    "    \n",
    "    #creo la mia immagine \n",
    "    command = \"docker build -t cloud_titanic .\"\n",
    "    os.system(command)\n",
    "\n",
    "    #command = \"docker run -it --entrypoint /bin/bash cloud_titanic\"\n",
    "    #command = \"docker run -it cloud_titanic .\"\n",
    "    #os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
